-----

## 0\. 분석 환경 설정 (라이브러리 임포트)

먼저 분석에 필요한 라이브러리들을 모두 임포트합니다.

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats

# K-Means
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

# Decision Tree
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import plot_tree

# 시각화 한글/마이너스 깨짐 방지 (환경에 맞게 설정)
# plt.rcParams['font.family'] = 'Malgun Gothic' # Windows
# plt.rcParams['font.family'] = 'AppleGothic'   # Mac
plt.rcParams['axes.unicode_minus'] = False

print("라이브러리 로드 완료.")
```

-----

## Day 3 (11/5 수): 📊 1차 분석 (Solo vs. Social)

**목표**: 'Solo' 그룹과 'Social' 그룹 간의 유의미한 차이(만족도, 장벽)를 통계적으로 검증합니다.

### 1\. [To-Do 1] 파생변수 생성

```python
# [leisure_model] '연령대' 생성 (예시: 20대~60대)
bins = [19, 29, 39, 49, 59, 69]
labels = ['20대', '30대', '40대', '50대', '60대']
leisure_model['연령대'] = pd.cut(leisure_model['나이'], bins=bins, labels=labels, right=True)
print("leisure_model '연령대' 컬럼 생성 완료.")

# [culture_analysis] '문화예술_관람횟수_총합' 생성
# (예시 컬럼명: '관람횟수_영화', '관람횟수_뮤지컬' 등 10개)
culture_cols = ['관람횟수_1', '관람횟수_2', ..., '관람횟수_10'] # 실제 10개 컬럼명 리스트
culture_analysis['문화예술_관람횟수_총합'] = culture_analysis[culture_cols].sum(axis=1)
print("culture_analysis '문화예술_관람횟수_총합' 컬럼 생성 완료.")
```

### 2\. [To-Do 2] 그룹 분리

```python
# '지난 1년간 ... 동반자(1순위)' 컬럼을 '동반자_1순위'라고 가정
solo_condition = (leisure_model['동반자_1순위'] == '혼자')

df_solo = leisure_model[solo_condition].copy()
df_social = leisure_model[~solo_condition].copy() # ~ (tild)는 'NOT'을 의미

print(f"Solo 그룹 샘플 수: {len(df_solo)}")
print(f"Social 그룹 샘플 수: {len(df_social)}")
```

### 3\. [To-Do 3] 가설 검증

**1. T-검정 (만족도 평균 차이)**

'지난 1년간 ... 만족도(1순위)' 컬럼을 '만족도\_1순위'라고 가정합니다.

```python
# 1. 등분산성 검정 (Levene's test)
satisfaction_solo = df_solo['만족도_1순위'].dropna() # 결측치 제거
satisfaction_social = df_social['만족도_1순위'].dropna()

levene_test = stats.levene(satisfaction_solo, satisfaction_social)
print(f"등분산성 검정 p-value: {levene_test.pvalue}")

# p-value에 따라 equal_var 설정
is_equal_var = (levene_test.pvalue > 0.05)

# 2. T-test 수행
t_test = stats.ttest_ind(satisfaction_solo, satisfaction_social, equal_var=is_equal_var)
print(f"T-test 결과 (T-statistic, p-value): {t_test}")

if t_test.pvalue < 0.05:
    print("결론: 두 그룹 간 만족도 평균은 통계적으로 유의미한 차이가 있습니다.")
else:
    print("결론: 두 그룹 간 만족도 평균 차이는 통계적으로 유의미하지 않습니다.")
```

**2. 교차분석 (카이제곱 검정 - 장벽 인식 차이)**

'여가활동 제약요인 - 여가 동반자 없음' 컬럼을 '장벽\_동반자없음' (응답=1, 미응답=0)이라고 가정합니다.

```python
# crosstab을 위해 두 프레임을 임시로 합치고 그룹 태그 부여
df_solo['group'] = 'Solo'
df_social['group'] = 'Social'
df_combined = pd.concat([df_solo, df_social])

# 1. 2x2 분할표(Contingency Table) 생성
contingency_table = pd.crosstab(df_combined['group'], df_combined['장벽_동반자없음'])
print("--- 분할표 ---")
print(contingency_table)

# 2. 카이제곱 검정 수행
chi2, p, dof, expected = stats.chi2_contingency(contingency_table)
print(f"\n카이제곱 검정 p-value: {p}")

if p < 0.05:
    print("결론: 그룹(Solo/Social)에 따라 '동반자 없음' 장벽 응답 비율에 유의미한 차이가 있습니다.")
else:
    print("결론: 그룹(Solo/Social)에 따라 '동반자 없음' 장벽 응답 비율에 차이가 없습니다.")
```

**3. [산출물] 시각화**

```python
plt.figure(figsize=(12, 5))

# 차트 1: 만족도 Box Plot
plt.subplot(1, 2, 1)
sns.boxplot(x='group', y='만족도_1순위', data=df_combined)
plt.title('그룹별 여가 만족도(1순위) 비교')

# 차트 2: 장벽 Bar Chart (응답 비율)
plt.subplot(1, 2, 2)
# 그룹별 '장벽_동반자없음' 응답 비율 계산
barrier_ratio = df_combined.groupby('group')['장벽_동반자없음'].mean().reset_index()
sns.barplot(x='group', y='장벽_동반자없음', data=barrier_ratio)
plt.title("그룹별 '동반자 없음' 장벽 응답 비율")
plt.ylabel('응답 비율')

plt.tight_layout()
plt.show()
```

-----

## Day 4 (11/6 목): 🤖 K-Means 모델링 (유형 '발견')

**목표**: `df_solo` 그룹 내부의 이질적인 하위 그룹(유형)을 K-Means로 발견합니다.

### 1\. [To-Do 1] 데이터 준비

```python
# K-Means에 사용할 변수 목록 선정 (예시)
# 만족도 5종, 제약요인 9종 (0/1), 나이, 소득 등
feature_list = [
    '만족도_1', '만족도_2', '만족도_3', '만족도_4', '만족도_5',
    '장벽_1', '장벽_2', ..., '장벽_9',
    '나이', '월평균_소득'
] # 실제 컬럼명으로 채워주세요

# df_solo에서 해당 변수들만 선택 (결측치 미리 처리 완료됨을 가정)
X_features = df_solo[feature_list]
print(f"K-Means 투입 변수 개수: {len(feature_list)}, 데이터 형태: {X_features.shape}")
```

### 2\. [To-Do 2] 스케일링

```python
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_features)

print("데이터 스케일링(표준화) 완료.")
```

### 3\. [To-Do 3] 모델 훈련

**1. 최적의 K값 찾기 (Elbow Method & Silhouette Score)**

```python
inertia_list = [] # WCSS (Inertia) 리스트
silhouette_list = [] # 실루엣 점수 리스트
K_range = range(2, 11) # K=2 부터 10까지 테스트

for k in K_range:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    kmeans.fit(X_scaled)
    inertia_list.append(kmeans.inertia_)
    
    # 실루엣 점수는 K=2 이상부터 계산 가능
    score = silhouette_score(X_scaled, kmeans.labels_)
    silhouette_list.append(score)
    print(f"K={k}, 실루엣 점수: {score:.3f}")

# Elbow Method 시각화
plt.figure(figsize=(10, 4))
plt.subplot(1, 2, 1)
plt.plot(K_range, inertia_list, marker='o')
plt.title('Elbow Method for Optimal K')
plt.xlabel('Number of clusters (K)')
plt.ylabel('Inertia (WCSS)')

# Silhouette Score 시각화
plt.subplot(1, 2, 2)
plt.plot(K_range, silhouette_list, marker='o')
plt.title('Silhouette Score for Optimal K')
plt.xlabel('Number of clusters (K)')
plt.ylabel('Silhouette Score')

plt.tight_layout()
plt.show()

# (시각화 결과 확인 후) 최적의 K 결정 (예: 3)
K_OPTIMAL = 3 
```

**2. 최종 모델 훈련 및 'cluster' 꼬리표 붙이기**

```python
# 결정된 최적의 K로 K-Means 모델 최종 훈련
kmeans_final = KMeans(n_clusters=K_OPTIMAL, random_state=42, n_init=10)
kmeans_final.fit(X_scaled)

# df_solo 원본에 'cluster' 꼬리표 붙이기
df_solo['cluster'] = kmeans_final.labels_

print(f"K={K_OPTIMAL}로 클러스터링 완료.")
print("df_solo 'cluster' 컬럼 생성 완료.")
print("\n클러스터별 샘플 수:")
print(df_solo['cluster'].value_counts().sort_index())
```

-----

## Day 5 (11/7 금): 🕵️ K-Means 결과 '해석' (Profiling)

**목표**: Day 4에서 생성된 `cluster` (0, 1, 2)가 각각 어떤 특성을 가진 그룹인지 해석하고 이름을 붙입니다.

### 1\. [To-Do 1] Track 1 (K-Means 투입 변수로 해석)

```python
# K-Means에 투입했던 변수들 + 'cluster'로 그룹별 평균/비율 비교
# (소득, 나이, 만족도는 mean() / 제약요인(0/1)은 mean()이 곧 응답 비율)
profile_track1 = df_solo.groupby('cluster')[feature_list].mean()

print("--- [Track 1] 클러스터별 K-Means 투입 변수 평균 ---")
# 소수점 2자리까지만 보기 좋게 출력
display(profile_track1.style.format("{:.2f}"))

# (팁) Radar Chart를 그리려면 이 profile_track1 데이터를 Min-Max 스케일링하여 사용합니다.
```

> **[해석 예시]**
> `profile_track1`의 출력 결과를 보고,
>
>   * Cluster 0: '소득' 평균은 높은데 '만족도' 평균은 낮고, '장벽\_동반자없음' 비율이 높다.
>   * Cluster 1: '소득' 평균이 낮고 '장벽\_경제적부담' 비율이 높다.
>   * Cluster 2: 전반적으로 '만족도'가 높고 '장벽' 응답률이 낮다.
>     ...와 같이 해석합니다.

### 2\. [To-Do 2] Track 2 (K-Means 미투입 변수 - 원본 활동 - 로 해석)

K-Means에 사용하지 않았던 `leisure` 원본의 91개 활동 참여 여부로 클러스터의 성향을 교차 확인합니다.

```python
# (가정) df_solo가 leisure 원본의 index를 유지하고 있거나, 'userID' 같은 공통 key가 있어야 함.
# 여기서는 index가 동일하다고 가정합니다.
# leisure_original: 91개 활동 컬럼이 있는 원본 데이터

# 'cluster' 꼬리표(df_solo)와 91개 활동 컬럼(leisure_original)을 병합
# df_solo는 leisure_model의 부분집합이므로, leisure_original과 merge
# (주의!) leisure_original이 Day 3의 leisure_model과 동일한 데이터인지 확인 필요
# 만약 leisure_model에 91개 활동 컬럼이 있다면, df_solo와 leisure_model을 merge할 필요 없이
# df_solo에 이미 91개 컬럼이 존재할 수 있습니다. 
# 여기서는 Day 3에서 91개 컬럼을 사용 안 했다고 가정하고, 원본과 합칩니다.

# (가정) 'userID'가 공통 키일 경우
if 'userID' in df_solo.columns and 'userID' in leisure_original.columns:
    merged_df = pd.merge(
        df_solo[['userID', 'cluster']],  # df_solo에서는 키와 클러스터 정보만
        leisure_original,               # 원본에서는 모든 정보 (특히 91개 활동)
        on='userID'
    )
# (가정) Index가 공통 키일 경우
else:
    merged_df = pd.merge(
        df_solo['cluster'],             # df_solo의 클러스터 정보 (Index 기준)
        leisure_original,               # 원본 데이터 (Index 기준)
        left_index=True, right_index=True
    )

print(f"Merge 완료. 데이터 형태: {merged_df.shape}")

# 91개 활동 컬럼 리스트 (예시)
activity_cols = ['Q1_활동_1', 'Q1_활동_2', ..., 'Q1_활동_91'] # 실제 91개 컬럼명 리스트

# 클러스터별 91개 활동 참여율(mean) 비교
profile_track2 = merged_df.groupby('cluster')[activity_cols].mean()

print("\n--- [Track 2] 클러스터별 91개 활동 참여율 평균 ---")
display(profile_track2.style.format("{:.3f}"))
```

> **[해석 예시]**
> `profile_track2`의 출력 결과를 보고,
>
>   * Cluster 0: '등산', '낚시' 등 혼자 하는 야외 활동 참여율이 높다.
>   * Cluster 1: '넷플릭스', '웹툰' 등 실내/저비용 활동 참여율이 높다.
>   * Cluster 2: '콘서트', '미술관' 등 문화 활동과 '지인모임' 등 사회적 활동 참여율이 높다.
>     ...와 같이 해석합니다.

### 3\. [산출물] 그룹 이름 붙이기 및 Radar Chart

  * **이름 붙이기**: Track 1과 Track 2의 해석을 종합합니다.
      * (예) Cluster 0 (고소득, 저만족도, 동반자장벽 높음, 야외활동 선호) ➡️ **'고립된 아웃도어형'**
      * (예) Cluster 1 (저소득, 경제적장벽 높음, 저비용활동 선호) ➡️ **'경제적 제약형'**
      * (예) Cluster 2 (고만족도, 저장벽, 문화/사교활동 선호) ➡️ **'자발적/풍요로운 Solo'**
  * **Radar Chart**: `profile_track1` (스케일링된) 데이터를 사용하여 3개 클러스터의 특성을 비교하는 Radar Chart를 그립니다. (matplotlib `polar` plot 또는 `plotly`의 `Scatterpolar` 사용)

-----

## Day 6 (11/8 토): 🌳 의사결정나무 및 교차 확인

**목표**: `df_solo` 그룹의 \*\*만족도(Y)\*\*에 영향을 미치는 \*\*핵심 원인(X)\*\*을 Decision Tree로 규명하고, 다른 데이터셋으로 교차 확인합니다.

### 1\. [To-Do 1] 의사결정나무

**1. Y 변수 생성 (범주형)**

Decision Tree 'Classifier'(분류기)를 사용하려면 Y(만족도)가 범주형이어야 합니다. 1-5점 만족도를 'High'/'Low'로 변환합니다.

```python
# '만족도_1순위' 사용
# (예: 1,2,3점 = Low(0), 4,5점 = High(1))
df_solo['satisfaction_group'] = np.where(df_solo['만족도_1순위'] >= 4, 1, 0) # 4점 이상 1(High), 미만 0(Low)
print("Y 변수 ('satisfaction_group') 생성 완료.")
print(df_solo['satisfaction_group'].value_counts(normalize=True))
```

**2. X, Y 변수 설정 및 학습/테스트 분리**

```python
# Y = 만족도 그룹
Y = df_solo['satisfaction_group']

# X = 원인 변수들 (제약요인, 소득, 나이, 연령대 등)
X_features_tree = [
    '장벽_1', '장벽_2', ..., '장벽_9',
    '월평균_소득', '나이', '연령대_encoded' # '연령대'가 문자열이면 더미 변수화(encoding) 필요
]
# (팁) '연령대'가 '20대', '30대' 등 문자열이면 pd.get_dummies(df_solo[...])로 변환
# 여기서는 X_features_tree에 숫자형 변수만 포함되었다고 가정합니다. (예: '나이')
X_features_tree_simple = ['장벽_동반자없음', '장벽_경제적부담', '월평균_소득', '나이'] # 간단한 예시

X = df_solo[X_features_tree_simple]

# 학습(80%) / 테스트(20%) 데이터 분리
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)
```

**3. 모델 훈련 및 시각화**

```python
# Decision Tree 훈련 (max_depth=3 또는 4로 설정해야 해석 용이)
dt_model = DecisionTreeClassifier(max_depth=3, random_state=42)
dt_model.fit(X_train, Y_train)

# (핵심) 시각화
plt.figure(figsize=(20, 10))
plot_tree(
    dt_model,
    feature_names=X.columns.tolist(),
    class_names=['Low_Satisfaction', 'High_Satisfaction'], # (0=Low, 1=High)
    filled=True,
    proportion=True,
    rounded=True,
    fontsize=10
)
plt.title("Decision Tree (Max Depth=3)", fontsize=20)
plt.show()
```

> **[결과 확인]**
> 시각화된 나무의 \*\*가장 위(Root Node)\*\*에 어떤 변수가 왔는지 확인합니다.
>
>   * '월평균\_소득 \<= 50.5' ➡️ 경제력이 만족도를 나누는 가장 첫 번째 기준.
>   * '장벽\_동반자없음 \<= 0.5' ➡️ 동반자 장벽 인식이 가장 첫 번째 기준.

### 2\. [To-Do 2] 교차 확인 (Cross-Analysis)

`culture_analysis` 데이터셋(Track 2)에서도 유사한 경향이 나타나는지 확인합니다.

```python
# 1. '문화예술_관람횟수_총합' == 0인 "미관람 집단" 필터링
df_no_culture = culture_analysis[culture_analysis['문화예술_관람횟수_총합'] == 0].copy()
print(f"문화예술 미관람 집단 샘플 수: {len(df_no_culture)}")

# 2. 이들의 '관람 걸림돌' (1순위) 확인
# (컬럼명 예시: '문화예술_관람걸림돌_1순위')
barrier_culture = df_no_culture['문화예술_관람걸림돌_1순위'].value_counts(normalize=True)

print("\n--- 문화예술 미관람 집단: 관람 걸림돌 (1순위) ---")
print(barrier_culture.head(5)) # 상위 5개

# 3. [산출물] 차트 5: Track 1 vs Track 2 장벽 비교
# (예시) Track 1(df_solo)의 장벽 1순위와 Track 2(df_no_culture)의 장벽 1순위 비교
# (예시 결과)
# Track 1 (leisure): '경제적 부담' (30%)
# Track 2 (culture): '관람료 부담' (35%)
# -> "두 데이터셋 모두 '경제적 문제'가 핵심 장벽임을 교차 확인"

# (시각화 예시)
plt.figure(figsize=(10, 5))
# (데이터가 준비되었다고 가정하고 barplot 그리기)
# sns.barplot(...)
plt.title("Track 1 (여가) vs Track 2 (문화) 핵심 장벽 비교")
plt.show()
```

-----

이 단계들을 순서대로 실행하시면, 처음에 계획했던 탄탄한 분석 스토리를 완성하실 수 있을 겁니다.

혹시 특정 코드 실행 중 오류가 발생하거나, K-Means 해석, Decision Tree 시각화 등 특정 단계에서 더 자세한 설명이 필요하시면 언제든 다시 질문해주세요.
